{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292e96df",
   "metadata": {},
   "source": [
    "# Sentiment Analysis for Predicting Stock Market Movements using News Headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3cb08",
   "metadata": {},
   "source": [
    "# Data Preparation and Preproccesing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a02b6a",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7ce332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import yfinance as yf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff00ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text cleaning\n",
    "import contractions\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1664c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\deiro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text pre-procesing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "#PoS Tagging\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f882530b",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e70aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/Combined_News_DJIA.csv', encoding = \"ISO-8859-1\", parse_dates=[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131d1fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the name of the headline columns\n",
    "cols = []\n",
    "for i in range(1,26):\n",
    "    col = (\"Top{}\".format(i))\n",
    "    cols.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2213d",
   "metadata": {},
   "source": [
    "### Extracting Stock data DJIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6934ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the start and end date\n",
    "start_date = '2008-07-15'\n",
    "end_date = '2016-07-02'\n",
    "tkr_djia ='^DJI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afdfd3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "DJIA = yf.download(tkr_djia, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "617de1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_djia=pd.DataFrame(DJIA)\n",
    "df_djia = df_djia.reset_index()\n",
    "df_djia = df_djia.sort_values(by=['Date'], ascending=False,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c509efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_djia['Date'] = df_djia['Date'].dt.date\n",
    "df_djia['Date'] = pd.to_datetime(df_djia['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3bc429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_djia['Next_1_Adj_Close'] = df_djia['Adj Close'].shift(-1)\n",
    "df_djia['Next_2_Adj_Close'] = df_djia['Adj Close'].shift(-2)\n",
    "df_djia['Next_3_Adj_Close'] = df_djia['Adj Close'].shift(-3)\n",
    "df_djia['Next_4_Adj_Close'] = df_djia['Adj Close'].shift(-4)\n",
    "df_djia['Next_5_Adj_Close'] = df_djia['Adj Close'].shift(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10381a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_djia['Label_1day'] = np.where(df_djia['Next_1_Adj_Close'] >= df_djia['Adj Close'], 1, 0)\n",
    "df_djia['Label_2day'] = np.where(df_djia['Next_2_Adj_Close'] >= df_djia['Adj Close'], 1, 0)\n",
    "df_djia['Label_3day'] = np.where(df_djia['Next_3_Adj_Close'] >= df_djia['Adj Close'], 1, 0)\n",
    "df_djia['Label_4day'] = np.where(df_djia['Next_4_Adj_Close'] >= df_djia['Adj Close'], 1, 0)\n",
    "df_djia['Label_5day'] = np.where(df_djia['Next_5_Adj_Close'] >= df_djia['Adj Close'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26ddfa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_djia.to_csv('dataset/upload_DJIA_table.csv',sep=',', encoding='utf-8',index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dec0460",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a72329c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date     0\n",
       "Label    0\n",
       "Top1     0\n",
       "Top2     0\n",
       "Top3     0\n",
       "Top4     0\n",
       "Top5     0\n",
       "Top6     0\n",
       "Top7     0\n",
       "Top8     0\n",
       "Top9     0\n",
       "Top10    0\n",
       "Top11    0\n",
       "Top12    0\n",
       "Top13    0\n",
       "Top14    0\n",
       "Top15    0\n",
       "Top16    0\n",
       "Top17    0\n",
       "Top18    0\n",
       "Top19    0\n",
       "Top20    0\n",
       "Top21    0\n",
       "Top22    0\n",
       "Top23    1\n",
       "Top24    3\n",
       "Top25    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1687e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(np.nan, 'no news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4ef6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that contains all the headlines from Top1 to Top25\n",
    "df[\"news\"] = df.filter(regex=(\"Top.*\")).apply(lambda x: ''.join(str(x.values)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccf6157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_cleaning(text):\n",
    "    # Remove the HTML tags    \n",
    "    text = re.sub('b\\\"|b\\'|\\\\\\\\|\\\\\\\"', '', text)\n",
    "    # Remove non ASCII\n",
    "    text = text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "    # Remove any punctuation\n",
    "    text = text.translate(text.maketrans('', '', string.punctuation))\n",
    "    # Remove any extra whitespace    \n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    # Change US to usa (in this way it is not confused with the pronoun us)\n",
    "    text = re.sub(r'US', 'usa', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower() \n",
    "    # Chage to the abbrevation    \n",
    "    text = re.sub(r\"united states of america\", \"usa\", text)\n",
    "    # Chage to the abbrevation \n",
    "    text = re.sub(r\"america\", \"usa\", text)\n",
    "    # Remove contractions \n",
    "    text = contractions.fix(text)\n",
    "    #Remove possessive noun\n",
    "    text = text.replace(\"'s\", \"\")\n",
    "    # Remove any HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)  \n",
    "    # Remove numbers \n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove any special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "      \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a455a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_news'] = df['news'].apply(lambda x: txt_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c17d7eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:03<00:00,  7.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(cols):\n",
    "    df[col] = df[col].apply(lambda x: txt_cleaning(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b758245",
   "metadata": {},
   "source": [
    "### Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57f06602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\deiro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\deiro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d786af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "df['tokenized'] = df['clean_news'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9e70cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize stopwords removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['news_without_stopwords'] = df['tokenized'].apply(lambda words: [word for word in words if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3043f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "df['news_stemmed'] = df['news_without_stopwords'].apply(lambda x: [stemmer.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44fa9396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PoS\n",
    "df['news_pos'] = df['news_without_stopwords'].apply(lambda x: nltk.pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c085e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemma without PoS\n",
    "lem = WordNetLemmatizer()\n",
    "df['news_lemmatized'] = df['news_without_stopwords'].apply(lambda words: [lem.lemmatize(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8ff1081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1989/1989 [00:06<00:00, 327.73it/s]\n"
     ]
    }
   ],
   "source": [
    "#Lemma with PoS\n",
    "lemma_list = []\n",
    "\n",
    "for words in tqdm(df['news_pos']):\n",
    "    tmp=[]\n",
    "    for lemma, pos in words:\n",
    "        if pos.startswith(\"NN\"):\n",
    "            tmp.append(lem.lemmatize(lemma, pos='n'))\n",
    "        elif pos.startswith('VB'):\n",
    "            tmp.append(lem.lemmatize(lemma, pos='v'))\n",
    "        elif pos.startswith('JJ'):\n",
    "            tmp.append(lem.lemmatize(lemma, pos='a'))\n",
    "        elif pos.startswith('R'):\n",
    "            tmp.append(lem.lemmatize(lemma, pos='r'))\n",
    "        else:\n",
    "            tmp.append(lem.lemmatize(lemma))\n",
    "            \n",
    "    lemma_list.append(tmp)\n",
    "    \n",
    "df['news_lemmatized_pos'] = lemma_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378817d1",
   "metadata": {},
   "source": [
    "### Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f01a25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d66333e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7511476c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['news_without_stopwords',\n",
       " 'news_stemmed',\n",
       " 'news_pos',\n",
       " 'news_lemmatized',\n",
       " 'news_lemmatized_pos']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = df.columns[30:].to_list()\n",
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "580b389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_array(arr):\n",
    "    return np.mean(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bba026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_classifier(model):\n",
    "    cv_scores = {}\n",
    "    \n",
    "    for att in tqdm(attributes):                \n",
    "        X_train = train_data[att]\n",
    "\n",
    "        cv = CountVectorizer(analyzer=lambda x: x) \n",
    "        X_train_tok = cv.fit_transform(X_train)\n",
    "\n",
    "        tfidf = TfidfTransformer() \n",
    "        X_train_vec = tfidf.fit_transform(X_train_tok)\n",
    "\n",
    "        ovr = OneVsRestClassifier(model)           \n",
    "        ovr.fit(X_train_vec, y_train)    \n",
    "\n",
    "        cv_scores[att] = cross_validate(ovr, X_train_tok, y_train, cv=10, scoring=scoring) \n",
    "        \n",
    "    \n",
    "    return  cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f642ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['f1_macro', 'f1_micro', 'f1_weighted', 'roc_auc', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19a22b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[df['Date']<'20141231']\n",
    "y_train = train_data.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47f4e473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:05<00:00, 13.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_without_stopwords</th>\n",
       "      <th>news_stemmed</th>\n",
       "      <th>news_pos</th>\n",
       "      <th>news_lemmatized</th>\n",
       "      <th>news_lemmatized_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>1.187515</td>\n",
       "      <td>1.000963</td>\n",
       "      <td>1.391213</td>\n",
       "      <td>1.179726</td>\n",
       "      <td>1.157479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.012540</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.011193</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.009560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_macro</th>\n",
       "      <td>0.499103</td>\n",
       "      <td>0.493788</td>\n",
       "      <td>0.502349</td>\n",
       "      <td>0.489184</td>\n",
       "      <td>0.493481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_micro</th>\n",
       "      <td>0.508075</td>\n",
       "      <td>0.501863</td>\n",
       "      <td>0.513665</td>\n",
       "      <td>0.498758</td>\n",
       "      <td>0.501242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <td>0.504298</td>\n",
       "      <td>0.498304</td>\n",
       "      <td>0.508189</td>\n",
       "      <td>0.494469</td>\n",
       "      <td>0.497888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_roc_auc</th>\n",
       "      <td>0.495094</td>\n",
       "      <td>0.504634</td>\n",
       "      <td>0.486561</td>\n",
       "      <td>0.495720</td>\n",
       "      <td>0.504232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.508075</td>\n",
       "      <td>0.501863</td>\n",
       "      <td>0.513665</td>\n",
       "      <td>0.498758</td>\n",
       "      <td>0.501242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  news_without_stopwords  news_stemmed  news_pos  \\\n",
       "fit_time                        1.187515      1.000963  1.391213   \n",
       "score_time                      0.012540      0.008991  0.011193   \n",
       "test_f1_macro                   0.499103      0.493788  0.502349   \n",
       "test_f1_micro                   0.508075      0.501863  0.513665   \n",
       "test_f1_weighted                0.504298      0.498304  0.508189   \n",
       "test_roc_auc                    0.495094      0.504634  0.486561   \n",
       "test_accuracy                   0.508075      0.501863  0.513665   \n",
       "\n",
       "                  news_lemmatized  news_lemmatized_pos  \n",
       "fit_time                 1.179726             1.157479  \n",
       "score_time               0.009884             0.009560  \n",
       "test_f1_macro            0.489184             0.493481  \n",
       "test_f1_micro            0.498758             0.501242  \n",
       "test_f1_weighted         0.494469             0.497888  \n",
       "test_roc_auc             0.495720             0.504232  \n",
       "test_accuracy            0.498758             0.501242  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "cs = model_classifier(model)\n",
    "cscores_log = pd.DataFrame(cs)\n",
    "cscores_log = cscores_log.applymap(mean_array)\n",
    "cscores_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50a0ee10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:25<00:00, 65.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_without_stopwords</th>\n",
       "      <th>news_stemmed</th>\n",
       "      <th>news_pos</th>\n",
       "      <th>news_lemmatized</th>\n",
       "      <th>news_lemmatized_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>4.537685</td>\n",
       "      <td>4.244043</td>\n",
       "      <td>6.088741</td>\n",
       "      <td>5.217611</td>\n",
       "      <td>5.060859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.037822</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>0.042194</td>\n",
       "      <td>0.033515</td>\n",
       "      <td>0.038786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_macro</th>\n",
       "      <td>0.474031</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>0.462986</td>\n",
       "      <td>0.487102</td>\n",
       "      <td>0.488516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_micro</th>\n",
       "      <td>0.487578</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.479503</td>\n",
       "      <td>0.501242</td>\n",
       "      <td>0.503727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <td>0.480928</td>\n",
       "      <td>0.507604</td>\n",
       "      <td>0.470529</td>\n",
       "      <td>0.494182</td>\n",
       "      <td>0.495768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_roc_auc</th>\n",
       "      <td>0.466076</td>\n",
       "      <td>0.494539</td>\n",
       "      <td>0.460229</td>\n",
       "      <td>0.477436</td>\n",
       "      <td>0.480608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.487578</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.479503</td>\n",
       "      <td>0.501242</td>\n",
       "      <td>0.503727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  news_without_stopwords  news_stemmed  news_pos  \\\n",
       "fit_time                        4.537685      4.244043  6.088741   \n",
       "score_time                      0.037822      0.028347  0.042194   \n",
       "test_f1_macro                   0.474031      0.500998  0.462986   \n",
       "test_f1_micro                   0.487578      0.514286  0.479503   \n",
       "test_f1_weighted                0.480928      0.507604  0.470529   \n",
       "test_roc_auc                    0.466076      0.494539  0.460229   \n",
       "test_accuracy                   0.487578      0.514286  0.479503   \n",
       "\n",
       "                  news_lemmatized  news_lemmatized_pos  \n",
       "fit_time                 5.217611             5.060859  \n",
       "score_time               0.033515             0.038786  \n",
       "test_f1_macro            0.487102             0.488516  \n",
       "test_f1_micro            0.501242             0.503727  \n",
       "test_f1_weighted         0.494182             0.495768  \n",
       "test_roc_auc             0.477436             0.480608  \n",
       "test_accuracy            0.501242             0.503727  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "cs = model_classifier(model)\n",
    "cscores_xg = pd.DataFrame(cs)\n",
    "cscores_xg = cscores_xg.applymap(mean_array)\n",
    "cscores_xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c141105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.16s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_without_stopwords</th>\n",
       "      <th>news_stemmed</th>\n",
       "      <th>news_pos</th>\n",
       "      <th>news_lemmatized</th>\n",
       "      <th>news_lemmatized_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.016829</td>\n",
       "      <td>0.014626</td>\n",
       "      <td>0.020447</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>0.019065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.012606</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>0.011963</td>\n",
       "      <td>0.017337</td>\n",
       "      <td>0.008107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_macro</th>\n",
       "      <td>0.445617</td>\n",
       "      <td>0.468964</td>\n",
       "      <td>0.451860</td>\n",
       "      <td>0.455696</td>\n",
       "      <td>0.461272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_micro</th>\n",
       "      <td>0.472050</td>\n",
       "      <td>0.490062</td>\n",
       "      <td>0.481366</td>\n",
       "      <td>0.481988</td>\n",
       "      <td>0.486957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <td>0.454947</td>\n",
       "      <td>0.477260</td>\n",
       "      <td>0.462298</td>\n",
       "      <td>0.464867</td>\n",
       "      <td>0.470717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_roc_auc</th>\n",
       "      <td>0.459224</td>\n",
       "      <td>0.464744</td>\n",
       "      <td>0.456236</td>\n",
       "      <td>0.459602</td>\n",
       "      <td>0.462977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.472050</td>\n",
       "      <td>0.490062</td>\n",
       "      <td>0.481366</td>\n",
       "      <td>0.481988</td>\n",
       "      <td>0.486957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  news_without_stopwords  news_stemmed  news_pos  \\\n",
       "fit_time                        0.016829      0.014626  0.020447   \n",
       "score_time                      0.012606      0.011076  0.011963   \n",
       "test_f1_macro                   0.445617      0.468964  0.451860   \n",
       "test_f1_micro                   0.472050      0.490062  0.481366   \n",
       "test_f1_weighted                0.454947      0.477260  0.462298   \n",
       "test_roc_auc                    0.459224      0.464744  0.456236   \n",
       "test_accuracy                   0.472050      0.490062  0.481366   \n",
       "\n",
       "                  news_lemmatized  news_lemmatized_pos  \n",
       "fit_time                 0.017050             0.019065  \n",
       "score_time               0.017337             0.008107  \n",
       "test_f1_macro            0.455696             0.461272  \n",
       "test_f1_micro            0.481988             0.486957  \n",
       "test_f1_weighted         0.464867             0.470717  \n",
       "test_roc_auc             0.459602             0.462977  \n",
       "test_accuracy            0.481988             0.486957  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "cs = model_classifier(model)\n",
    "cscores_gau = pd.DataFrame(cs)\n",
    "cscores_gau = cscores_gau.applymap(mean_array)\n",
    "cscores_gau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ac1d291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [09:10<00:00, 110.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_without_stopwords</th>\n",
       "      <th>news_stemmed</th>\n",
       "      <th>news_pos</th>\n",
       "      <th>news_lemmatized</th>\n",
       "      <th>news_lemmatized_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>8.374074</td>\n",
       "      <td>8.072280</td>\n",
       "      <td>8.335169</td>\n",
       "      <td>7.964488</td>\n",
       "      <td>7.846040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>1.885935</td>\n",
       "      <td>1.752652</td>\n",
       "      <td>1.881442</td>\n",
       "      <td>1.749889</td>\n",
       "      <td>1.730186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_macro</th>\n",
       "      <td>0.419758</td>\n",
       "      <td>0.456773</td>\n",
       "      <td>0.374995</td>\n",
       "      <td>0.432975</td>\n",
       "      <td>0.434538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_micro</th>\n",
       "      <td>0.531677</td>\n",
       "      <td>0.538509</td>\n",
       "      <td>0.520497</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.526708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <td>0.441216</td>\n",
       "      <td>0.474409</td>\n",
       "      <td>0.400429</td>\n",
       "      <td>0.452511</td>\n",
       "      <td>0.453676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_roc_auc</th>\n",
       "      <td>0.500171</td>\n",
       "      <td>0.511694</td>\n",
       "      <td>0.494713</td>\n",
       "      <td>0.506065</td>\n",
       "      <td>0.513814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.531677</td>\n",
       "      <td>0.538509</td>\n",
       "      <td>0.520497</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.526708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  news_without_stopwords  news_stemmed  news_pos  \\\n",
       "fit_time                        8.374074      8.072280  8.335169   \n",
       "score_time                      1.885935      1.752652  1.881442   \n",
       "test_f1_macro                   0.419758      0.456773  0.374995   \n",
       "test_f1_micro                   0.531677      0.538509  0.520497   \n",
       "test_f1_weighted                0.441216      0.474409  0.400429   \n",
       "test_roc_auc                    0.500171      0.511694  0.494713   \n",
       "test_accuracy                   0.531677      0.538509  0.520497   \n",
       "\n",
       "                  news_lemmatized  news_lemmatized_pos  \n",
       "fit_time                 7.964488             7.846040  \n",
       "score_time               1.749889             1.730186  \n",
       "test_f1_macro            0.432975             0.434538  \n",
       "test_f1_micro            0.528571             0.526708  \n",
       "test_f1_weighted         0.452511             0.453676  \n",
       "test_roc_auc             0.506065             0.513814  \n",
       "test_accuracy            0.528571             0.526708  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC()\n",
    "cs = model_classifier(model)\n",
    "cscores_svm = pd.DataFrame(cs)\n",
    "cscores_svm = cscores_svm.applymap(mean_array)\n",
    "cscores_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f27f5030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [08:19<00:00, 99.83s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_without_stopwords</th>\n",
       "      <th>news_stemmed</th>\n",
       "      <th>news_pos</th>\n",
       "      <th>news_lemmatized</th>\n",
       "      <th>news_lemmatized_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>9.231701</td>\n",
       "      <td>7.678864</td>\n",
       "      <td>11.951187</td>\n",
       "      <td>8.359783</td>\n",
       "      <td>8.116455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.107499</td>\n",
       "      <td>0.095057</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>0.091508</td>\n",
       "      <td>0.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_macro</th>\n",
       "      <td>0.467093</td>\n",
       "      <td>0.453240</td>\n",
       "      <td>0.430672</td>\n",
       "      <td>0.459037</td>\n",
       "      <td>0.448368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_micro</th>\n",
       "      <td>0.524224</td>\n",
       "      <td>0.516770</td>\n",
       "      <td>0.508696</td>\n",
       "      <td>0.521118</td>\n",
       "      <td>0.519876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1_weighted</th>\n",
       "      <td>0.481690</td>\n",
       "      <td>0.468926</td>\n",
       "      <td>0.448310</td>\n",
       "      <td>0.474363</td>\n",
       "      <td>0.464869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_roc_auc</th>\n",
       "      <td>0.509299</td>\n",
       "      <td>0.494789</td>\n",
       "      <td>0.478015</td>\n",
       "      <td>0.485604</td>\n",
       "      <td>0.466545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.524224</td>\n",
       "      <td>0.516770</td>\n",
       "      <td>0.508696</td>\n",
       "      <td>0.521118</td>\n",
       "      <td>0.519876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  news_without_stopwords  news_stemmed   news_pos  \\\n",
       "fit_time                        9.231701      7.678864  11.951187   \n",
       "score_time                      0.107499      0.095057   0.098810   \n",
       "test_f1_macro                   0.467093      0.453240   0.430672   \n",
       "test_f1_micro                   0.524224      0.516770   0.508696   \n",
       "test_f1_weighted                0.481690      0.468926   0.448310   \n",
       "test_roc_auc                    0.509299      0.494789   0.478015   \n",
       "test_accuracy                   0.524224      0.516770   0.508696   \n",
       "\n",
       "                  news_lemmatized  news_lemmatized_pos  \n",
       "fit_time                 8.359783             8.116455  \n",
       "score_time               0.091508             0.089400  \n",
       "test_f1_macro            0.459037             0.448368  \n",
       "test_f1_micro            0.521118             0.519876  \n",
       "test_f1_weighted         0.474363             0.464869  \n",
       "test_roc_auc             0.485604             0.466545  \n",
       "test_accuracy            0.521118             0.519876  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "cs = model_classifier(model)\n",
    "cscores_rf = pd.DataFrame(cs)\n",
    "cscores_rf = cscores_rf.applymap(mean_array)\n",
    "cscores_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20707a7b",
   "metadata": {},
   "source": [
    "## Data pre processing to headlines Top1 to Top25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "441ac38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:47<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(cols):\n",
    "    # Tokenize\n",
    "    df[col] = df[col].apply(lambda x: word_tokenize(x))     \n",
    "    # Remove stopwords\n",
    "    df[col] = df[col].apply(lambda words: [word for word in words if word not in stop_words]) \n",
    "    # Stemming\n",
    "    df[col] = df[col].apply(lambda x: [stemmer.stem(word) for word in x])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c085c12e",
   "metadata": {},
   "source": [
    "## Merging with stock data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79c7a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels=df_djia[['Date','Label_1day','Label_2day','Label_3day','Label_4day','Label_5day']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4e01aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df,df_labels,on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20430629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['tokenized','news_without_stopwords','news_pos', 'news_lemmatized','news_lemmatized_pos'], axis=1, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34d2ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset/pre_process_all_news_days.csv',sep=',', encoding='utf-8',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3fe5f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df[['Date','clean_news','news_stemmed','Label','Label_1day',\n",
    "       'Label_2day', 'Label_3day', 'Label_4day', 'Label_5day']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef475258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small.to_csv('dataset/pre_process_news_days.csv',sep=',', encoding='utf-8',index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
